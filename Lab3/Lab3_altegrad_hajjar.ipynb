{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ALTEGRAD_2021_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "# Transfer learning for NLP\n",
        "## ALTEGRAD - Lab session 3\n",
        "#### Moussa Kamal Eddine, Hadi Abdine (Dascim LIX)\n",
        "##### 23 November 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(num_embeddings=ntoken, embedding_dim=nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, nhid) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid) \n",
        "        src = self.pos_encoder(src)#fill me\n",
        "        output = self.transformer_encoder(src, src_mask)#fill me\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)#fill me\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers)#fill me\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)#fill me \n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src, src_mask)#fill me\n",
        "        # classifier model\n",
        "        output = self.classifier(x)#fill me\n",
        "        return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dde3f78-79fb-442b-8f8e-1811b302d353"
      },
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRYN9X_xCeHD"
      },
      "source": [
        "**It is the right shape: we have 1 example of 6 timesteps from a 100-word vocab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62da537-bfca-4042-f946-d952b2f82792"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-30 10:58:54--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-11-30 10:58:54 (9.61 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a09f5cc-21b5-4836-84f7-5d585ad2564c"
      },
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx+4 #+4 because the first 4 are reserved to special tokens\n",
        "\n",
        "ind2token = {k:v for (v,k) in token2ind.items()} #fill me\n",
        "\n",
        "print(ind2token[1111])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]]\n",
        "        for word in sequence[:self.max_len]:\n",
        "            if word in self.token2ind:\n",
        "                source_sequence+=[self.token2ind[word]]\n",
        "            else:\n",
        "                source_sequence+=[self.token2ind[\"<oov>\"]]\n",
        "        #fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
        "        \n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    \n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1]#fill me \n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1]#fill me\n",
        "        target = target.to(device)\n",
        "        loss =  criterion(output, target)#fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
        "        #fill me step 4\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() \n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "source": [
        "ntokens = len(ind2token)#fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54845a54-ef55-4dc3-85e0-fc3a5f92ecad"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-30 10:58:55--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-11-30 10:58:55 (97.8 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e815196-c679-4c1a-fed9-e2d91959ad11"
      },
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 50\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |    50/ 3125 steps | loss 9.54635 | ppl 13993.518\n",
            "| epoch   1 |   100/ 3125 steps | loss 7.82299 | ppl 2497.370\n",
            "| epoch   1 |   150/ 3125 steps | loss 7.56317 | ppl 1925.942\n",
            "| epoch   1 |   200/ 3125 steps | loss 7.40515 | ppl 1644.424\n",
            "| epoch   1 |   250/ 3125 steps | loss 7.32120 | ppl 1512.021\n",
            "| epoch   1 |   300/ 3125 steps | loss 7.25620 | ppl 1416.858\n",
            "| epoch   1 |   350/ 3125 steps | loss 7.14362 | ppl 1266.009\n",
            "| epoch   1 |   400/ 3125 steps | loss 7.17822 | ppl 1310.572\n",
            "| epoch   1 |   450/ 3125 steps | loss 7.00970 | ppl 1107.321\n",
            "| epoch   1 |   500/ 3125 steps | loss 6.97275 | ppl 1067.150\n",
            "| epoch   1 |   550/ 3125 steps | loss 6.98981 | ppl 1085.515\n",
            "| epoch   1 |   600/ 3125 steps | loss 6.88697 | ppl  979.426\n",
            "| epoch   1 |   650/ 3125 steps | loss 6.89450 | ppl  986.829\n",
            "| epoch   1 |   700/ 3125 steps | loss 6.86172 | ppl  955.013\n",
            "| epoch   1 |   750/ 3125 steps | loss 6.78505 | ppl  884.527\n",
            "| epoch   1 |   800/ 3125 steps | loss 6.71706 | ppl  826.381\n",
            "| epoch   1 |   850/ 3125 steps | loss 6.74600 | ppl  850.651\n",
            "| epoch   1 |   900/ 3125 steps | loss 6.69930 | ppl  811.841\n",
            "| epoch   1 |   950/ 3125 steps | loss 6.66679 | ppl  785.866\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.60951 | ppl  742.119\n",
            "| epoch   1 |  1050/ 3125 steps | loss 6.57500 | ppl  716.946\n",
            "| epoch   1 |  1100/ 3125 steps | loss 6.58375 | ppl  723.248\n",
            "| epoch   1 |  1150/ 3125 steps | loss 6.64379 | ppl  767.999\n",
            "| epoch   1 |  1200/ 3125 steps | loss 6.54501 | ppl  695.763\n",
            "| epoch   1 |  1250/ 3125 steps | loss 6.57004 | ppl  713.398\n",
            "| epoch   1 |  1300/ 3125 steps | loss 6.49118 | ppl  659.299\n",
            "| epoch   1 |  1350/ 3125 steps | loss 6.48670 | ppl  656.353\n",
            "| epoch   1 |  1400/ 3125 steps | loss 6.54827 | ppl  698.036\n",
            "| epoch   1 |  1450/ 3125 steps | loss 6.43347 | ppl  622.327\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.43913 | ppl  625.860\n",
            "| epoch   1 |  1550/ 3125 steps | loss 6.44759 | ppl  631.179\n",
            "| epoch   1 |  1600/ 3125 steps | loss 6.42952 | ppl  619.877\n",
            "| epoch   1 |  1650/ 3125 steps | loss 6.39433 | ppl  598.445\n",
            "| epoch   1 |  1700/ 3125 steps | loss 6.29935 | ppl  544.220\n",
            "| epoch   1 |  1750/ 3125 steps | loss 6.33600 | ppl  564.535\n",
            "| epoch   1 |  1800/ 3125 steps | loss 6.28869 | ppl  538.447\n",
            "| epoch   1 |  1850/ 3125 steps | loss 6.32764 | ppl  559.834\n",
            "| epoch   1 |  1900/ 3125 steps | loss 6.36188 | ppl  579.334\n",
            "| epoch   1 |  1950/ 3125 steps | loss 6.29735 | ppl  543.130\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.31393 | ppl  552.208\n",
            "| epoch   1 |  2050/ 3125 steps | loss 6.25490 | ppl  520.555\n",
            "| epoch   1 |  2100/ 3125 steps | loss 6.26193 | ppl  524.230\n",
            "| epoch   1 |  2150/ 3125 steps | loss 6.29851 | ppl  543.761\n",
            "| epoch   1 |  2200/ 3125 steps | loss 6.25563 | ppl  520.936\n",
            "| epoch   1 |  2250/ 3125 steps | loss 6.22902 | ppl  507.258\n",
            "| epoch   1 |  2300/ 3125 steps | loss 6.23121 | ppl  508.369\n",
            "| epoch   1 |  2350/ 3125 steps | loss 6.20329 | ppl  494.371\n",
            "| epoch   1 |  2400/ 3125 steps | loss 6.25562 | ppl  520.931\n",
            "| epoch   1 |  2450/ 3125 steps | loss 6.18726 | ppl  486.511\n",
            "| epoch   1 |  2500/ 3125 steps | loss 6.21770 | ppl  501.546\n",
            "| epoch   1 |  2550/ 3125 steps | loss 6.15906 | ppl  472.981\n",
            "| epoch   1 |  2600/ 3125 steps | loss 6.16926 | ppl  477.833\n",
            "| epoch   1 |  2650/ 3125 steps | loss 6.10949 | ppl  450.107\n",
            "| epoch   1 |  2700/ 3125 steps | loss 6.17511 | ppl  480.638\n",
            "| epoch   1 |  2750/ 3125 steps | loss 6.17620 | ppl  481.159\n",
            "| epoch   1 |  2800/ 3125 steps | loss 6.14027 | ppl  464.179\n",
            "| epoch   1 |  2850/ 3125 steps | loss 6.13644 | ppl  462.402\n",
            "| epoch   1 |  2900/ 3125 steps | loss 6.17584 | ppl  480.987\n",
            "| epoch   1 |  2950/ 3125 steps | loss 6.14408 | ppl  465.951\n",
            "| epoch   1 |  3000/ 3125 steps | loss 6.12170 | ppl  455.639\n",
            "| epoch   1 |  3050/ 3125 steps | loss 6.08502 | ppl  439.229\n",
            "| epoch   1 |  3100/ 3125 steps | loss 6.10366 | ppl  447.494\n",
            "| epoch   2 |    50/ 3125 steps | loss 6.03469 | ppl  417.669\n",
            "| epoch   2 |   100/ 3125 steps | loss 5.99664 | ppl  402.075\n",
            "| epoch   2 |   150/ 3125 steps | loss 5.90258 | ppl  365.982\n",
            "| epoch   2 |   200/ 3125 steps | loss 5.95129 | ppl  384.249\n",
            "| epoch   2 |   250/ 3125 steps | loss 5.95134 | ppl  384.268\n",
            "| epoch   2 |   300/ 3125 steps | loss 5.91641 | ppl  371.078\n",
            "| epoch   2 |   350/ 3125 steps | loss 5.96354 | ppl  388.984\n",
            "| epoch   2 |   400/ 3125 steps | loss 5.91693 | ppl  371.270\n",
            "| epoch   2 |   450/ 3125 steps | loss 5.97041 | ppl  391.666\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.85990 | ppl  350.691\n",
            "| epoch   2 |   550/ 3125 steps | loss 5.91383 | ppl  370.122\n",
            "| epoch   2 |   600/ 3125 steps | loss 5.88984 | ppl  361.346\n",
            "| epoch   2 |   650/ 3125 steps | loss 5.93650 | ppl  378.607\n",
            "| epoch   2 |   700/ 3125 steps | loss 5.89304 | ppl  362.504\n",
            "| epoch   2 |   750/ 3125 steps | loss 5.91496 | ppl  370.538\n",
            "| epoch   2 |   800/ 3125 steps | loss 5.89447 | ppl  363.025\n",
            "| epoch   2 |   850/ 3125 steps | loss 5.84904 | ppl  346.901\n",
            "| epoch   2 |   900/ 3125 steps | loss 5.94491 | ppl  381.805\n",
            "| epoch   2 |   950/ 3125 steps | loss 5.88563 | ppl  359.830\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.84705 | ppl  346.212\n",
            "| epoch   2 |  1050/ 3125 steps | loss 5.82038 | ppl  337.100\n",
            "| epoch   2 |  1100/ 3125 steps | loss 5.82445 | ppl  338.475\n",
            "| epoch   2 |  1150/ 3125 steps | loss 5.91788 | ppl  371.622\n",
            "| epoch   2 |  1200/ 3125 steps | loss 5.90366 | ppl  366.377\n",
            "| epoch   2 |  1250/ 3125 steps | loss 5.90843 | ppl  368.129\n",
            "| epoch   2 |  1300/ 3125 steps | loss 5.82941 | ppl  340.157\n",
            "| epoch   2 |  1350/ 3125 steps | loss 5.85211 | ppl  347.968\n",
            "| epoch   2 |  1400/ 3125 steps | loss 5.86425 | ppl  352.216\n",
            "| epoch   2 |  1450/ 3125 steps | loss 5.85364 | ppl  348.502\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.86876 | ppl  353.811\n",
            "| epoch   2 |  1550/ 3125 steps | loss 5.87269 | ppl  355.202\n",
            "| epoch   2 |  1600/ 3125 steps | loss 5.83451 | ppl  341.896\n",
            "| epoch   2 |  1650/ 3125 steps | loss 5.77458 | ppl  322.008\n",
            "| epoch   2 |  1700/ 3125 steps | loss 5.80540 | ppl  332.087\n",
            "| epoch   2 |  1750/ 3125 steps | loss 5.82388 | ppl  338.282\n",
            "| epoch   2 |  1800/ 3125 steps | loss 5.73408 | ppl  309.228\n",
            "| epoch   2 |  1850/ 3125 steps | loss 5.78294 | ppl  324.713\n",
            "| epoch   2 |  1900/ 3125 steps | loss 5.85894 | ppl  350.354\n",
            "| epoch   2 |  1950/ 3125 steps | loss 5.84707 | ppl  346.220\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.78663 | ppl  325.912\n",
            "| epoch   2 |  2050/ 3125 steps | loss 5.79911 | ppl  330.007\n",
            "| epoch   2 |  2100/ 3125 steps | loss 5.79441 | ppl  328.459\n",
            "| epoch   2 |  2150/ 3125 steps | loss 5.82116 | ppl  337.363\n",
            "| epoch   2 |  2200/ 3125 steps | loss 5.74512 | ppl  312.660\n",
            "| epoch   2 |  2250/ 3125 steps | loss 5.86437 | ppl  352.261\n",
            "| epoch   2 |  2300/ 3125 steps | loss 5.80987 | ppl  333.577\n",
            "| epoch   2 |  2350/ 3125 steps | loss 5.76629 | ppl  319.352\n",
            "| epoch   2 |  2400/ 3125 steps | loss 5.77082 | ppl  320.802\n",
            "| epoch   2 |  2450/ 3125 steps | loss 5.79519 | ppl  328.715\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.78853 | ppl  326.532\n",
            "| epoch   2 |  2550/ 3125 steps | loss 5.86512 | ppl  352.524\n",
            "| epoch   2 |  2600/ 3125 steps | loss 5.77560 | ppl  322.336\n",
            "| epoch   2 |  2650/ 3125 steps | loss 5.86293 | ppl  351.755\n",
            "| epoch   2 |  2700/ 3125 steps | loss 5.72233 | ppl  305.616\n",
            "| epoch   2 |  2750/ 3125 steps | loss 5.77464 | ppl  322.028\n",
            "| epoch   2 |  2800/ 3125 steps | loss 5.77044 | ppl  320.678\n",
            "| epoch   2 |  2850/ 3125 steps | loss 5.73841 | ppl  310.570\n",
            "| epoch   2 |  2900/ 3125 steps | loss 5.77263 | ppl  321.383\n",
            "| epoch   2 |  2950/ 3125 steps | loss 5.76851 | ppl  320.060\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.74209 | ppl  311.716\n",
            "| epoch   2 |  3050/ 3125 steps | loss 5.71880 | ppl  304.539\n",
            "| epoch   2 |  3100/ 3125 steps | loss 5.80497 | ppl  331.947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea1d587-87e0-4f3e-8fe3-0cb1d1de43f4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device) \n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt') \n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict']) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-30 11:10:07--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.1’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   164MB/s    in 0.5s    \n",
            "\n",
            "2021-11-30 11:10:07 (164 MB/s) - ‘pretrained_model_4layers.pt.1’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f22926-dea5-42a3-e035-05569eb52ba0"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "--2021-11-30 11:10:13--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-11-30 11:10:13 (21.5 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind =  torch.argmax(out[-1], dim=1)#fill me\n",
        "    return next_token_ind, out\n",
        "    \n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    n = 0\n",
        "    curr = \"\"\n",
        "    while n<=max_len and curr!='<eos>':\n",
        "        curr = ind2token[int(infer_next_token(sent)[0])]\n",
        "        encoded = s.encode_as_pieces(curr)\n",
        "        sent += \" \" + s.decode_pieces(encoded)\n",
        "        n+=1\n",
        "    return sent\n",
        "    # to be implemented"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e978d510-477a-4dbd-c2d7-e63687382eee"
      },
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques . <eos>'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86532a78-3932-4182-9d7b-8c932140d24b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-30 11:10:13--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "\rtrain.review.spm      0%[                    ]       0  --.-KB/s               \rtrain.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-11-30 11:10:13 (26.3 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2021-11-30 11:10:13--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-30 11:10:13 (33.2 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2021-11-30 11:10:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  3.65MB/s    in 0.5s    \n",
            "\n",
            "2021-11-30 11:10:14 (3.65 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2021-11-30 11:10:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-30 11:10:14 (52.1 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    #to be implemented\n",
        "    model.eval() #set to validation mode\n",
        "    with torch.no_grad():\n",
        "      correct = 0\n",
        "      all=0\n",
        "      for idx, data in enumerate(data_loader):\n",
        "          src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "              device\n",
        "          )\n",
        "          input = data[0].to(device)\n",
        "          output = model(input, src_mask)\n",
        "          output = output[-1]\n",
        "          output = output.view(-1, output.shape[-1])\n",
        "          output = output.argmax(dim=1)\n",
        "          target = data[1]\n",
        "          target = target.to(device)\n",
        "          correct += (target==output).sum().item()\n",
        "          all+=len(target)\n",
        "          \n",
        "    model.train() #set it back to training mode\n",
        "    return correct/all\n",
        "\n",
        "        "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281b99d1-bfef-41fe-f280-e32bb1bcf59c"
      },
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.82384 | ppl    2.279\n",
            "| epoch   1 |   100/  200 steps | loss 0.75569 | ppl    2.129\n",
            "| epoch   1 |   150/  200 steps | loss 0.70303 | ppl    2.020\n",
            "| epoch   2 |    50/  200 steps | loss 0.72526 | ppl    2.065\n",
            "| epoch   2 |   100/  200 steps | loss 0.69657 | ppl    2.007\n",
            "| epoch   2 |   150/  200 steps | loss 0.71029 | ppl    2.035\n",
            "| epoch   3 |    50/  200 steps | loss 0.72526 | ppl    2.065\n",
            "| epoch   3 |   100/  200 steps | loss 0.67974 | ppl    1.973\n",
            "| epoch   3 |   150/  200 steps | loss 0.67373 | ppl    1.962\n",
            "| epoch   4 |    50/  200 steps | loss 0.67075 | ppl    1.956\n",
            "| epoch   4 |   100/  200 steps | loss 0.54855 | ppl    1.731\n",
            "| epoch   4 |   150/  200 steps | loss 0.51489 | ppl    1.673\n",
            "| epoch   5 |    50/  200 steps | loss 0.46336 | ppl    1.589\n",
            "| epoch   5 |   100/  200 steps | loss 0.36986 | ppl    1.448\n",
            "| epoch   5 |   150/  200 steps | loss 0.48260 | ppl    1.620\n",
            "| epoch   6 |    50/  200 steps | loss 0.31922 | ppl    1.376\n",
            "| epoch   6 |   100/  200 steps | loss 0.30969 | ppl    1.363\n",
            "| epoch   6 |   150/  200 steps | loss 0.41305 | ppl    1.511\n",
            "| epoch   7 |    50/  200 steps | loss 0.25924 | ppl    1.296\n",
            "| epoch   7 |   100/  200 steps | loss 0.25007 | ppl    1.284\n",
            "| epoch   7 |   150/  200 steps | loss 0.25779 | ppl    1.294\n",
            "| epoch   8 |    50/  200 steps | loss 0.25969 | ppl    1.297\n",
            "| epoch   8 |   100/  200 steps | loss 0.21936 | ppl    1.245\n",
            "| epoch   8 |   150/  200 steps | loss 0.30246 | ppl    1.353\n",
            "| epoch   9 |    50/  200 steps | loss 0.24907 | ppl    1.283\n",
            "| epoch   9 |   100/  200 steps | loss 0.20266 | ppl    1.225\n",
            "| epoch   9 |   150/  200 steps | loss 0.16351 | ppl    1.178\n",
            "| epoch  10 |    50/  200 steps | loss 0.11948 | ppl    1.127\n",
            "| epoch  10 |   100/  200 steps | loss 0.14966 | ppl    1.161\n",
            "| epoch  10 |   150/  200 steps | loss 0.11038 | ppl    1.117\n",
            "| epoch  11 |    50/  200 steps | loss 0.06691 | ppl    1.069\n",
            "| epoch  11 |   100/  200 steps | loss 0.15745 | ppl    1.171\n",
            "| epoch  11 |   150/  200 steps | loss 0.10530 | ppl    1.111\n",
            "| epoch  12 |    50/  200 steps | loss 0.07628 | ppl    1.079\n",
            "| epoch  12 |   100/  200 steps | loss 0.12090 | ppl    1.129\n",
            "| epoch  12 |   150/  200 steps | loss 0.11057 | ppl    1.117\n",
            "| epoch  13 |    50/  200 steps | loss 0.08151 | ppl    1.085\n",
            "| epoch  13 |   100/  200 steps | loss 0.05854 | ppl    1.060\n",
            "| epoch  13 |   150/  200 steps | loss 0.12387 | ppl    1.132\n",
            "| epoch  14 |    50/  200 steps | loss 0.13445 | ppl    1.144\n",
            "| epoch  14 |   100/  200 steps | loss 0.14306 | ppl    1.154\n",
            "| epoch  14 |   150/  200 steps | loss 0.08643 | ppl    1.090\n",
            "| epoch  15 |    50/  200 steps | loss 0.07968 | ppl    1.083\n",
            "| epoch  15 |   100/  200 steps | loss 0.03343 | ppl    1.034\n",
            "| epoch  15 |   150/  200 steps | loss 0.04258 | ppl    1.044\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.84351 | ppl    2.325\n",
            "| epoch   1 |   100/  200 steps | loss 0.70898 | ppl    2.032\n",
            "| epoch   1 |   150/  200 steps | loss 0.66021 | ppl    1.935\n",
            "| epoch   2 |    50/  200 steps | loss 0.59238 | ppl    1.808\n",
            "| epoch   2 |   100/  200 steps | loss 0.51861 | ppl    1.680\n",
            "| epoch   2 |   150/  200 steps | loss 0.56608 | ppl    1.761\n",
            "| epoch   3 |    50/  200 steps | loss 0.47041 | ppl    1.601\n",
            "| epoch   3 |   100/  200 steps | loss 0.56895 | ppl    1.766\n",
            "| epoch   3 |   150/  200 steps | loss 0.50023 | ppl    1.649\n",
            "| epoch   4 |    50/  200 steps | loss 0.47400 | ppl    1.606\n",
            "| epoch   4 |   100/  200 steps | loss 0.49748 | ppl    1.645\n",
            "| epoch   4 |   150/  200 steps | loss 0.45996 | ppl    1.584\n",
            "| epoch   5 |    50/  200 steps | loss 0.39360 | ppl    1.482\n",
            "| epoch   5 |   100/  200 steps | loss 0.47036 | ppl    1.601\n",
            "| epoch   5 |   150/  200 steps | loss 0.45436 | ppl    1.575\n",
            "| epoch   6 |    50/  200 steps | loss 0.39882 | ppl    1.490\n",
            "| epoch   6 |   100/  200 steps | loss 0.40613 | ppl    1.501\n",
            "| epoch   6 |   150/  200 steps | loss 0.45717 | ppl    1.580\n",
            "| epoch   7 |    50/  200 steps | loss 0.40840 | ppl    1.504\n",
            "| epoch   7 |   100/  200 steps | loss 0.33921 | ppl    1.404\n",
            "| epoch   7 |   150/  200 steps | loss 0.39434 | ppl    1.483\n",
            "| epoch   8 |    50/  200 steps | loss 0.41285 | ppl    1.511\n",
            "| epoch   8 |   100/  200 steps | loss 0.30170 | ppl    1.352\n",
            "| epoch   8 |   150/  200 steps | loss 0.37800 | ppl    1.459\n",
            "| epoch   9 |    50/  200 steps | loss 0.34976 | ppl    1.419\n",
            "| epoch   9 |   100/  200 steps | loss 0.34032 | ppl    1.405\n",
            "| epoch   9 |   150/  200 steps | loss 0.36294 | ppl    1.438\n",
            "| epoch  10 |    50/  200 steps | loss 0.36720 | ppl    1.444\n",
            "| epoch  10 |   100/  200 steps | loss 0.27746 | ppl    1.320\n",
            "| epoch  10 |   150/  200 steps | loss 0.30125 | ppl    1.352\n",
            "| epoch  11 |    50/  200 steps | loss 0.25770 | ppl    1.294\n",
            "| epoch  11 |   100/  200 steps | loss 0.42997 | ppl    1.537\n",
            "| epoch  11 |   150/  200 steps | loss 0.27124 | ppl    1.312\n",
            "| epoch  12 |    50/  200 steps | loss 0.28492 | ppl    1.330\n",
            "| epoch  12 |   100/  200 steps | loss 0.35689 | ppl    1.429\n",
            "| epoch  12 |   150/  200 steps | loss 0.24444 | ppl    1.277\n",
            "| epoch  13 |    50/  200 steps | loss 0.26837 | ppl    1.308\n",
            "| epoch  13 |   100/  200 steps | loss 0.38093 | ppl    1.464\n",
            "| epoch  13 |   150/  200 steps | loss 0.30815 | ppl    1.361\n",
            "| epoch  14 |    50/  200 steps | loss 0.23317 | ppl    1.263\n",
            "| epoch  14 |   100/  200 steps | loss 0.29313 | ppl    1.341\n",
            "| epoch  14 |   150/  200 steps | loss 0.25585 | ppl    1.292\n",
            "| epoch  15 |    50/  200 steps | loss 0.30437 | ppl    1.356\n",
            "| epoch  15 |   100/  200 steps | loss 0.22673 | ppl    1.254\n",
            "| epoch  15 |   150/  200 steps | loss 0.24094 | ppl    1.272\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "030253d9-89de-4c3b-b98a-e025954d5145"
      },
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ep = range(1,epochs+1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(ep, from_scratch_valid_acc, label = \"From Scratch\", color = \"blue\")\n",
        "plt.plot(ep, pretrained_valid_acc, label = \"Pretrained\", color = \"orange\")\n",
        "plt.legend()\n",
        "from google.colab import files\n",
        "plt.savefig(\"accuracy.png\")\n",
        "files.download(\"accuracy.png\") \n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a7c47d90-fed9-42e0-bf02-7ae2e9f70f02\", \"accuracy.png\", 14721)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zV9fXH8ddJCHuFKRC27BUgIEqROhhaBf05ADtwoq2g1o4farXW2pY6CjiqRYtQUfFXFMWBikWKCMQkyEYBGZKwwg4yss7vj88NuYSQ3IR787335jwfj/u4+96TQN73cz/fzxBVxRhjTPSK8boAY4wxoWVBb4wxUc6C3hhjopwFvTHGRDkLemOMiXJVvC6gqEaNGmmbNm28LsMYYyJKWlraPlVtXNx9YRf0bdq0ITU11esyjDEmoojI9rPdZ103xhgT5SzojTEmylnQG2NMlLOgN8aYKGdBb4wxUc6C3hhjopwFvTHGRLmwG0dvjDFh7cg3kPEe1GoDdbtAnfMhtprXVZXIgt6YaJGXDQfSIHMx7F0M32+HppdAi6uhyeCwD6Owpwqbp8GKX0Le8cLbJQZqtYO6naFeZ3det4s7r9bAu3r9WNAbE4jcY7BvOcTEQf3uUDXe64og9zjsT3ahvve/sG9ZYQDV7QI1E+Dbl2Hjc1ClNjQbBi2uguY/gurFzpQ3Z3NiH3x5O6S/C+cNhf4vQPZhOPK132kD7F4A+ScLn1etsS/4/U71ukDNVhATW2HlW9AbU5y8ky5Edy+EvZ+5EM3PKby/RnOo192F/qnzrlClVuhqyjkCmUtdsGcuhv1f+moSiE+E88dBk4uh8Q+gehP3nNxjsGeh62rIeB92vOUe32iAa+m3uMrVLxK6uiPdrgWw7GeQfQD6TIZO97hWPECD3qc/Nj8Pjm2Hw77gL/gQSJ8LJ/cVPi62OtTpeOYHQJ2OUKVm0H8ECbetBJOSktTWujEVLj/XdXvsWehOmV/4WscCDfq6LpCml7iv74fXweG1cGgtHFkPeScKX6dW2yLh3x3qdipft8nJ/bD388JgP/gVaD5IFWiQBE0HQ+OLofFFULV+6a+n6l4j4z13OpDmq7mNC3zr4jld3klY9SB8/Tf3IX7R6xDfq/yvd2JfkW8Avg+Do1sBXw7X7wVXrizXy4tImqomFXufBb2plDQfDq12LfY9C12Y5ma5++r3gKaXumBvcnHJ3TT5eXB0S2HwF3wIHPkGNNc9RmJdS61+d6jXrfBDoHZ7iPH7Un1sJ2T6gn3vYvc64Fp/DQe4Wppc7FrjwfjmcGwn7PzAhf7uT90HW5Xa0GyoC/3mVxZ+M6hsDm+ApTfBwZXQ4RfQ+8mQtLQB11DI2uSCnxhodV25XsaC3hhV94dU0GLfs8h9FQcXwk0v8YX7D4MTbnnZkLXRF/6+D4BDa+Hot5xqvcVUc1/Xa7WFQ2vg6GZ3e5XarvulINgbJIW+lZ17/PQunuMZgEDDCyDhahf859rFo+pCLfd7yPvenRec8o5DfG+ocV7QfqRy17j5RVhxv/t3uGC6+/kjgAW9qXxUXUt7z2e+YP8MTux299VsBeddWthqr5lQcXXlHnNf1ws+AA6tcwFfr6vrhmlysetvj/Hw8Jmqa8me6uLx/T3Wag3Nr4L4nu7nOC2oi1wvNsyPuW9SZxMTBy1vcH3gjS6omJ/V34lMSL7N/cznDYULZ0CNZhVfRzlZ0JvKQdWF0paZ7o/12Hfu9urnFbbYz7vUtaDt4GPgju2EnR/6ungWFBlaGOu6karUgthahZeLnk67r+aZt8VUgR1zYct0d9C5YX/oOAFa3VAxxwx2fQLLxrpveYl/Pf2Aa4Q456AXkeHAVCAWeFlVJxW5vxUwE6jve8xEVf3Qd98DwG1AHnCPqn5c0ntZ0JsyO5YB22a5gD+ywXWJNL8CzrvchXvdzhbswZJ73I0eORXQVYP7u83Jgq3/go3PuuMc1ZvC+XdCh7tC07rOOwkrH4BvJgfngKuHzinoRSQW2AgMAdKBFGCMqq73e8w04CtVfUFEugIfqmob3+U3gP5Ac+BToKOq5p3t/SzoTUByj0H6Oy7c93zqugQaXQTtxkKrGwMbhWLCl+a7A8TfPOO+TUisa913uscdNwjGh8vh9fDFGHdQvsPdvgOuNc79dT1SUtAH0hHYH9isqlt8LzYbGAms93uMAnV9l+sBO32XRwKzVfUksFVENvteb1mZfwpjVCFzCWydCd/9233Fr9kKuj4IbX8GdTt4XaEJFolxo3+aDYWszbDxedets/0NaNAPOk1wH+jl6dZRhU0vwFe/cgdcB7/nhpdGsUCCvgWww+96OlD0SMmjwCciMgGoBVzu99zlRZ7bougbiMg4YBxAq1atAqnbVCZHt7qv81v/5Q6wVqkFLa93rfcmgyOuL9WUUZ3zoe9k6PkYbH3Vdess+xl89WvXrXP+XVCzeWCvdSITlt8KO993M4UHzCjzSJ89e2DRIujSBbp2hSoRMO00WCWOAWao6tMiciHwqoh0D/TJqjoNmAau6yZINZlIlpMF381xrfe9/wXEHVDt/nto+T8QV9vrCk1Fi6sDHX8BHX5e2K2z9nFY9xfXrdNxgptjcLZunZ0fw/KxkH0Q+kxx3wrK2EiYPx/GjoXMTHe9enXo1Qv69i08de0KcXHn+LMGWSBBnwG09Lue4LvN323AcABVXSYi1YFGAT7XGCc/zy03sGUm7HjbDcer0wF6Pg5tfwq17NuewQV5syHulPWtr1vnn75unSQX+K1HFXbr5J3wHXCd4g64XvKJGyJaBidPwgMPwOTJ0KMHvPkm7NoFaWnu9Oqr8Pe/u8eGY/gHcjC2Cu5g7GW4kE4BblLVdX6PmQ+8qaozRKQL8B9cF01X4HUKD8b+B+hgB2ND6Pvtbjp/nfZeVxK4I9+4cN/2KhxLh7h60Ho0tB1bcgvNmAI5R93/n2+ecRPjqjeB9uPgvMsg7V53wLXjeEh8oswHXDduhDFjYMUKGD8ennzShbm//HzYtKkw+NPS3OOzfJOtq1eHnj0hKSl04R+M4ZVXAlNwQyenq+qfROQxIFVV5/lG17wE1MYdmP2tqn7ie+5DwK1ALnCfqs4v6b0s6M/Bt9Mh5S630FX9XtDqeteXXa+z15WdTtWF+873XffM/mQ3qqLZMBfuCSPctH9jykrVdetsfNbN8EXdCpIDXoEWPyrzS736KvziF1CtGkyfDiNHBv780sK/WjXX8g9W+NuEqWiXnwcrf+sWXzpviBtDvuMttzAXuPVVWl7vgr9eN29ayPk5boGujPfdxJuC6f7xidDmJ9Dmx95PfzfRJetbN8Er4Zoy/986csQF/GuvweDBMGsWJARhAnVp4Z+YCF99Vb7XtqCPZtmH4YvRsOsj6HgP9Hm6cPr8sQw323DHHLdIFuomDxWEfv2eoQ39k/th50cu2Hd9BDmH3WSmppf6Vku8yvrdTdhJSYHRo2HbNnj0UXjwQYgN4dLx+fmweTMUxN5NN5XvdSzoo1XWZvjv1e683/NuPfKzOb7bTTD67t+wd5GbkFL7fBf4ra6H+D7nHvoFXTIFa6Ts+8K9T/Wmvg0vrnKzVcN8xExuLnz3nWt5bd5ceP7tt1CjBnToAOeff/p5kyZ2KCHS5efD00+7YG/eHF5/HQYO9LqqwFnQR6PdC2HJ9W542A/muFUXA3Ui0xf6c2DPf0Dz3JrkBX36DfsHnlqnumR84X70W3d7fKIL9hZXQ8OksBvrnpsL27efHuQF51u3Qo7fHiO1arlAb98ejh0rfEye35CCOnXcY4p+AJx/PjRtah8C4W73bvjZz2DBArjuOnjpJYgPg03EysKCPtps/Duk3eO6YQbPg9rtyv9aJ/dD+jzXvbN7gQvumi2h5XUu+BtdeGZIn9wPO+f7dckcKeySSbjaBXytlsW/XwUqCPOiQb5pkwvq3NzCxxaEeXGt9fPOOzOoc3JKfm3/D4Hatc/+2vYh4L2PP3Yhf+QITJ0Kd9wRmf8mFvTRIj/HDRXb9IIL04GvQVzd0p8XqOxDLry/mwO7PnZ7X9Zo5kK/2RVuWd2M92Df0tO7ZFpc7bpkQrmNXhn861/w+OOBhXnB5eLCvLwKPgTO9m3Bv6bataFdO6hZ082wLDjFxpb/csH1Jk3c5J6iQwGNk50NDz0ETz0F3bvD7NnQrZvXVZWfBX00OHkAltzg1lbv8lvo9efQbi6ccwQyPnAt/Z0fFm6XF5/o22v0arfFXph1yezaVRjeV155erAHM8zLKyfnzP7/rVvhxAn3AZCX587P5bL/t4mOHeHFF+GSS7z7mcPRpk1ubHxamhtd89RT7vhLJDvXRc2M1w5vcAddj+2AATOh3c9C/55xdaHNGHfKOepa8XW7hEWXTEkeecS11ObMceEebuLiXF9/+xDOZ1N1Bxb/8x/4+c/h0kvh5ptdmDVsGLr3jRQFY+Pj4mDuXLjmGq8rCr3wao6ZM+2cD58McPuZXraoYkK+qDjfPqJhHvJr1rhJLXffHZ4hX1FEXNfN0KHudzJxohsH3rmz69YKsy/xFSYry/XF/+xn0Ls3rFpVOUIeLOjDlyp8PRn+e5U72DosBRpf6HVVYe03v4G6deHhh72uJHzUrAl/+YublNOhg+uzHzLEdV1UJqmp0KePmwD1hz/AZ59By/ButwSVBX04yjvp9q5ccb+b1TdkiU0sKsXHH7vTww9DgwZeVxN+evSAJUvcwlspKe76n/7kurmiWcHY+IsucguTLVrkuvdCOQEqHFnQh5sTe2HhZbDlFej+MPzg32EzmiVc5eW51nzbtq7bxhQvJsb12W/YACNGwO9+57owlizxurLQSEtzB+R//Wu46ipYuRIGDfK6Km9Y0IeTg6vho35wIA0GznYbLYTZqJZwNHOm64ueNMktFGVK1rw5/N//wXvvwdGjLvzuvBMOHvS6snOXk+OWEB440C0WtmQJvPACvPVW5f6mZykSLna8AwsuAs2Fyz9362mbUh096lqmAwbADTd4XU1kueoqWLcO7r8fXn7Z7Zj05puRebB27143d6JNG7dOze7dbu349HS46y7vh9V6zYLea6qw7s/w+bVQt6s76Nqw2KGwphhPP+3Gzj/9tP0xl0ft2u53l5LiVmccPdp1d2zd6nVlgUlLc0NHW7Z0x2e6d4f333cHm++7D+rbHvGABb23co/D0p/Aqoeg9U1w+X8D3/vSsGsXPPEEXH+9O9hmyq9PH0hOhilT4PPP3QzRJ588fc2fcJGT42axFnTPzJnjli3YsMEdkP/Rj9zxCFPIfh1eyMt2/fCfDobtr7tZrhfNKvPON5Xdww+7P/pJk7yuJDrExsK997rAHDIEfvtb6NcPvvzS68oc/+6ZMWPcJt1TpkBGBjz3nJsnYIpnM2NDLS8bDq9zwV5wOrQK8rPdaJpBc6FlJZm1EUSrV7vJUffdF9pZppVRy5bwzjtu1uiECe74x913u+GYdYO4tFKg0tLgmWdcKz47G4YNg2nT4IorrOUeKFvrJpjOCPVUt1dlvm+wclw9aNDHrRET3xeaXGxdNeU0fLhraW7eXLlHU4Ta4cPuYPfzz7vROs8+C9deG/r3zclxI2WeeQaWLXPHEm6+2e3Z2qlT6N8/EtlaN6FwWqin+lrqxYR6p3tdsDfo62a42nDJc1YwOepvf7OQD7V69Vy4/+QnMG4c/M//uMlWzZq5333Dhu686OWC6/Xru9U0A7Vnj2utv/gi7NzplrKYMsWFfL16Ifsxo5616AMRUKj3Pf1koR4SeXluX81jx2D9ehs3X5FyclzoL1gABw4Ung4eLHlIZr16pX8g1K7tuosKumeGD3fdRsOHW/dMoKxFfy52/wcWj4Tc7931glA/raXe3sb2VZAZM2DtWvj3vy3kK1pcnBtzf//9p9+el+e6eAqCf//+0z8Iil7fsqX4D4jatd23BuueCT4L+pLknYSUn0P1ZtDrcWiQ5GupW6h7oWBy1IUXuu3eTHiIjS1snZdFfr77gNi/34V+p07eHOytDAIKehEZDkwFYoGXVXVSkfsnAwVbG9QEmqhqfd99ecAa333fqeqIYBReIb6ZClmb4Ifzoflwr6up9J56ys14fPtt+6yNBjExbl/WSNubNRKVGvQiEgs8DwwB0oEUEZmnqusLHqOqv/R7/ASgt99LHFfVxOCVXEGO74K1f3Q7KVnIe27nTjeB58YbXYveGBO4QA5z9Ac2q+oWVc0GZgMjS3j8GOCNYBTnqZUPuIOtff7mdSWGwslRf/mL15UYE3kCCfoWwA6/6+m+284gIq2BtsBCv5uri0iqiCwXkWJnBonION9jUjMzMwMsPYT2JcPWmdD5fqhTibcqChOrV8Mrr7hRGO3aeV2NMZEn2AOXRgNzVNVve2Ja+4b83ARMEZEz5jGq6jRVTVLVpMaNGwe5pDLSfEidADWaQbcHva3FAG6t+fr13YFYY0zZBRL0GYD/plsJvtuKM5oi3TaqmuE73wIs4vT++/CzZSYcSIHEJyCujtfVVHoffQSffOJ2BbKDdsaUTyBBnwJ0EJG2IlIVF+bzij5IRDoD8cAyv9viRaSa73IjYCCwvuhzw0b2YVj1ADS6ENr82OtqKr3cXLc7UPv28ItfeF2NMZGr1FE3qporIuOBj3HDK6er6joReQxIVdWC0B8NzNbTp9p2Af4hIvm4D5VJ/qN1ws7aP7qt/Aa/b+P3wsCMGW5jjDlzoGpVr6sxJnLZEggFDn8NH/aAdmPhgpcr/v3NaY4ehQ4dXGv+88/tc9eY0tgSCKVRhRW/hCo13drwxnNPPukmR73zjoW8MefKgh5g5wew6yM3Zr56E6+rqfQyMlzQjxoFF1zgdTXGRD5bFy7vJKTdB3W7QMfxXldjcJOj8vJscpQxwWIt+m+mwNFv4ZKPISbO62oqvVWr3EHYX/0K2rb1uhpjokPlbtEf2+lG2iSMhGZDva6m0lN1wynj4+FBm6tmTNBU7hb9yomQnwO9n/a6EoObHPXpp25HIZscZUzwVN4WfeYy2PYqdPk11LHdpb1WMDnq/PPh5z/3uhpjokvlbNFrPqRNgBrNoesDXldjcIuWrV/vNoS2yVHGBFflDPotr7h9Xy+cBXG1va6m0svKciNtfvADuPZar6sxJvpUvqDPPuTWmm90EbS5yetqDG7M/J498O67NjnKmFCofEG/5jE4uQ8u+chSJQxkZLgtAkePtslRxoRK5ToYe3gDbHwW2t8ODfp4XY3BrTFvk6OMCa3KE/SqbgZslVrQ609eV1PpqboDrzNnwr33Qps2XldkTPSqPEGf8R7s/gR6/AGqe7yLVSW3Zg0MHQrXXw/dutnkKGNCrXIEfd4Jtzplva7QMbp3sNi/341iCUeZmW6MfGIipKXBM8/AihVum0BjTOhUjqD/ejIc3QJ9pkT1ejb790P37pCQ4PZZTU/3uiInOxueftpNhnrpJRg/HjZvdpt9x0XvP4cxYSP6g/5YBqz7EyRcA82GeF1NSP3yl7BvH1x2Gfztb25RsLFjXVeJF1TdkMlu3dys1x/8wNUydSo0aOBNTcZURtEf9Cv/F/JzoU90r2fz4Yfw6qvwwAPw9tvw7bdun9U5c6BnT7jiCli40IVvRVi9GoYMgWuuca32+fPhgw+gS5eKeX9jTKHoDvrML2Dba249m9rtvK4mZA4fhjvvdC3nhx5yt7Vp41rOO3bA44+7vvDLLoOkJJg9260tEwp798Jdd0Hv3vDVV/Dss27p4eHDQ/N+xpjSRW/Q5+dB6j1QowV0i+71bH77W9i5E6ZPh2rVTr+vQQMX/tu3w7Rpbi/WMWPcfqzPPOOuB8PJk27iU4cO8M9/uv73TZtcf7z1wxvjregN+i2vwMEV0PtJN3Y+Si1c6AL8/vuhf/+zP656dbjjDtiwwe3D2qKFG7/eqpX7INi9u3zvr+per1s3dwB40CDXDz9livXDGxMuojPosw/Bqgeg8Q+g9WivqwmZ77+H2293o1n+8IfAnhMTAyNHwpIlsHQpXHKJm5Xapo37IPj668Dff/Vq1x107bXum8RHH8H770PnzuX6cYwxIRJQ0IvIcBH5RkQ2i8jEYu6fLCIrfaeNInLI776xIrLJdxobzOLPas0f4OR+6PtMVK9n89BDsHWr6yqpWbPsz7/wQjc79Ztv4JZbYNYsd7C04IPgbAdu9+51xwR693b97889586HDTu3n8cYEyKqWuIJiAW+BdoBVYFVQNcSHj8BmO673ADY4juP912OL+n9+vbtq+fk0DrV12NVk8ed2+uEuSVLVEVU7747eK+5Z4/qI4+oNmyoCqoDBqi+9ZZqbq67/8QJ1SeeUK1TR7VKFdX77lM9cCB472+MKT8gVc+Sq4G06PsDm1V1i6pmA7OBkSU8fgzwhu/yMGCBqh5Q1YPAAiB04y9UIe1eqFIHej4esrfx2okTcNtt0LJlcBcDa9LEdQF9951rpe/dC9dd57piHnsMunZ1B34HD4a1a2HyZNvyz5hIEEjQtwB2+F1P9912BhFpDbQFFpbluSIyTkRSRSQ1MzMzkLqLl/4u7P4Uekb3ejZ/+IPrbnnpJahTJ/ivX7Mm3H03bNwI//d/Lsx//3uoUQM+/hjeew86dQr++xpjQiPY69GPBuaoal5ZnqSq04BpAElJSeWb0pN3AlbcD/W6QYfo3XQ0Lc1t1HHrrW5hsFCKjYUbbnCLj23b5r5BVKl8OxgYE/ECadFnAC39rif4bivOaAq7bcr63HNzYg9Uawh9p0btejbZ2S7gmzRxa8dUFBG3nIKFvDGRKZA/3RSgg4i0xYX0aOCMPfhEpDPugOsyv5s/Bv4sIgU9uUOB0MxeqtUahn0Z1aNsJk1yQxrffddWfDTGBK7UoFfVXBEZjwvtWNyImnUi8hjuKO8830NHA7N9R38LnntARP6I+7AAeExVDwT3R/ATxSG/dq1bymDMGBgxwutqjDGRRPxyOSwkJSVpamqq12WEldxcuOgiN2Z+/XpoHL3HmY0x5SQiaaqaVNx91usaASZPhpQUtxiZhbwxpqyicwmEKLJxIzzyiJuteuONXldjjIlEFvRhLD/fTYyqXh3+/veoPgRhjAkh67oJY3//u1tz5pVXoHlzr6sxxkQqa9GHqW3bYOJEt1DY2IpZCs4YE6Us6MOQqlsyWAT+8Q/rsjHGnBvruglD06fDp5+6rpvWrb2uxhgT6axFH2YyMuBXv4KLL3ZrvhtjzLmyoA8jqvDzn7s1bf75T7cblDHGnCvrugkjs2e7JYCfftptD2iMMcFgbcYwsXcvTJgAF1zgNu02xphgsaAPExMmQFaW67KJjfW6GmNMNLGgDwNz57qdnB5+GLp187oaY0y0saD32IED8ItfQGIi/O//el2NMSYa2cFYj91/P2RmwocfQlx0boxljPGYteg99NFHMHOma8n37u11NcaYaGVB75EjR2DcOOjSxfXNG2NMqFjXjUf++ldIT4elS90yxMYYEyrWovfIp5/CoEEwYIDXlRhjop0FvQdOnoSVK93kKGOMCTULeg+sXOnWs7GgN8ZUBAt6DyQnu3PrtjHGVISAgl5EhovINyKyWUQmnuUxN4rIehFZJyKv+92eJyIrfad5wSo8ki1fDi1auJMxxoRaqaNuRCQWeB4YAqQDKSIyT1XX+z2mA/AAMFBVD4pIE7+XOK6qiUGuO6IlJ1u3jTGm4gTSou8PbFbVLaqaDcwGRhZ5zB3A86p6EEBV9wa3zOiRmQlbtljQG2MqTiBB3wLY4Xc93Xebv45ARxH5QkSWi8hwv/uqi0iq7/ZrzrHeiPfll+7cgt4YU1GCNWGqCtAB+CGQACwWkR6qeghoraoZItIOWCgia1T1W/8ni8g4YBxAq1atglRSeEpOdjtHJSV5XYkxprIIpEWfAbT0u57gu81fOjBPVXNUdSuwERf8qGqG73wLsAg4Y1UXVZ2mqkmqmtS4ceMy/xCRZPly6NEDatXyuhJjTGURSNCnAB1EpK2IVAVGA0VHz7yDa80jIo1wXTlbRCReRKr53T4QWE8llZ/vum6s28YYU5FK7bpR1VwRGQ98DMQC01V1nYg8BqSq6jzffUNFZD2QB/xGVfeLyEXAP0QkH/ehMsl/tE5ls3EjHD5sQW+MqVgB9dGr6ofAh0Vue8TvsgL3+07+j1kK9Dj3MqNDwUQpC3pjTEWymbEVKDkZ6tSBzp29rsQYU5lY0Feg5GTo3982/zbGVCwL+gpy7BisWmXdNsaYimdBX0FWrIC8PAt6Y0zFs6CvIHYg1hjjFQv6CpKcDK1bQ9OmXldijKlsLOgrSHKyrT9vjPGGBX0F2LULvvvOum2MMd6woK8A1j9vjPGSBX0FSE6GKlWg9xnLuRljTOhZ0FeA5GTo1Qtq1PC6EmNMZWRBH2J5eZCSYt02xhjvWNCH2IYNcPSojbgxxnjHgj7Eli9359aiN8Z4xYI+xJKTIT4eOnTwuhJjTGVlQR9iBStWinhdiTGmsrKgD6GjR2HdOuu2McZ4y4I+hFJT3T6xdiDWGOMlC/oQKjgQ27+/t3UYYyo3C/oQSk6G88+Hhg29rsQYU5lZ0IeIqgt66583xnjNgj5E0tPdqpUW9MYYrwUU9CIyXES+EZHNIjLxLI+5UUTWi8g6EXnd7/axIrLJdxobrMLDXcGKlXYg1hjjtSqlPUBEYoHngSFAOpAiIvNUdb3fYzoADwADVfWgiDTx3d4A+D2QBCiQ5nvuweD/KOElORmqVXOLmRljjJcCadH3Bzar6hZVzQZmAyOLPOYO4PmCAFfVvb7bhwELVPWA774FwPDglB7eli93yxJXrep1JcaYyi6QoG8B7PC7nu67zV9HoKOIfCEiy0VkeBmeG3VyciAtzfrnjTHhodSumzK8Tgfgh0ACsFhEegT6ZBEZB4wDaNWqVZBK8s7atXD8uAW9MSY8BNKizwBa+l1P8N3mLx2Yp6o5qroV2IgL/kCei6pOU9UkVU1q3LhxWeoPS7Z1oDEmnAQS9ClABxFpKyJVgdHAvCKPeQfXmkdEGuG6crYAHwNDRSReROKBob7bolpyMjRuDG3bel2JMcYE0Jxnu4wAABH4SURBVHWjqrkiMh4X0LHAdFVdJyKPAamqOo/CQF8P5AG/UdX9ACLyR9yHBcBjqnogFD9IOFm+3LXmbcVKY0w4EFX1uobTJCUlaWpqqtdllNuhQ279+T/+EX73O6+rMcZUFiKSpqpJxd1nM2ODLMX33cX6540x4cKCPsgKDsT26+dtHcYYU8CCPsiSk6FLF6hf3+tKjDHGsaAPIlux0hgTjizog2jrVsjMtKA3xoQXC/ogsolSxphwZEEfRMnJUKMG9Ah48QdjjAk9C/ogSk6Gvn2hSrBWEDLGmCCwoA+Skyfhq69soxFjTPixoA+SVatc2Fv/vDEm3FjQB4kdiDXGhCsL+iBJToZmzSAhwetKjDHmdBb0QVIwUcpWrDTGhBsL+iDYvx82b7YDscaY8GRBHwRffunOrX/eGBOOLOiDYPlyiImBpGJXgjbGGG9Z0AdBcjJ06wa1a3tdiTHGnMmC/hypuq4b67YxxoQrC/pztGkTHDxoQW+MCV8W9OeoYKKUjbgxxoQrC/pztHy565vv0sXrSowxpngW9OcoOdntDxsb63UlxhhTvICCXkSGi8g3IrJZRCYWc//NIpIpIit9p9v97svzu31eMIv32vHjbjEz6583xoSzUldOF5FY4HlgCJAOpIjIPFVdX+Shb6rq+GJe4riqJp57qeHnq68gN9eC3hgT3gJp0fcHNqvqFlXNBmYDI0NbVmSwFSuNMZEgkKBvAezwu57uu62o60RktYjMEZGWfrdXF5FUEVkuItecS7HhJjkZWrVyq1YaY0y4CtbB2PeANqraE1gAzPS7r7WqJgE3AVNEpH3RJ4vION+HQWpmZmaQSgq95cutNW+MCX+BBH0G4N9CT/Dddoqq7lfVk76rLwN9/e7L8J1vARYBvYu+gapOU9UkVU1q3LhxmX4Ar+zZA9u3W9AbY8JfIEGfAnQQkbYiUhUYDZw2ekZE/DsvRgAbfLfHi0g13+VGwECg6EHciGT988aYSFHqqBtVzRWR8cDHQCwwXVXXichjQKqqzgPuEZERQC5wALjZ9/QuwD9EJB/3oTKpmNE6ESk52Y2d79PH60qMCa2cnBzS09M5ceKE16UYoHr16iQkJBAXFxfwc0RVQ1hS2SUlJWlqaqrXZZTq8svdGjdpaV5XYkxobd26lTp16tCwYUPEtlDzlKqyf/9+srKyaNu27Wn3iUia73joGWxmbDnk5dmKlabyOHHihIV8mBARGjZsWOZvVxb05fD115CVZUFvKg8L+fBRnn8LC/pysAOxxphIYkFfDsnJUK8edOzodSXGVA6xsbEkJiaeOm3bti1k77Vnzx6uuuoqevXqRdeuXbnyyiuD8rqLFi1i6dKlJT5m27ZtdO/ePSjv56/UUTfmTMnJrjUfYx+TxlSIGjVqsHLlymLvU1VUlZgg/UE+8sgjDBkyhHvvvReA1atXB/zc3NxcqlQpPlYXLVpE7dq1ueiii4JSZ1lY0JfR99/DmjUwYoTXlRhT8e67D86St+WWmAhTppTtOdu2bWPYsGFccMEFpKWl8eGHH/Lcc88xf/58RITf/e53jBo1ikWLFvH73/+e+vXrs2bNGm688UZ69OjB1KlTOX78OO+88w7t258+WX/Xrl0MHTr01PWePXueuvzXv/6VWbNmERMTwxVXXMGkSZP44Q9/SGJiIkuWLGHMmDF07NiRxx9/nOzsbBo2bMhrr73G8ePHefHFF4mNjWXWrFk8++yzdOzYkbvuuostW7YA8MILL9C8eXPy8vK44447WLp0KS1atODdd9+lRo0a5f8FY0FfZqmpkJ9v/fPGVKTjx4+TmOgWwW3bti2TJ09m06ZNzJw5kwEDBvDWW2+xcuVKVq1axb59++jXrx8XX3wxAKtWrWLDhg00aNCAdu3acfvtt/Pll18ydepUnn32WaYU+ZS5++67GTVqFM899xyXX345t9xyC82bN2f+/Pm8++67JCcnU7NmTQ4cOHDqOdnZ2RQMCz948CDLly9HRHj55Zd54oknePrpp7nrrruoXbs2v/71rwEYNWoUgwcPZu7cueTl5XH06FEOHjzIpk2beOONN3jppZe48cYbeeutt/jJT35yTr8/C/oyKjgQ27+/t3UY44WytryDpWjXzbZt22jdujUDfHt4FrSmY2Njadq0KYMHDyYlJYW6devSr18/mvlWHmzfvv2p1nqPHj347LPPznivYcOGsWXLFj766CPmz59P7969Wbt2LZ9++im33HILNWvWBKBBgwannjNq1KhTl9PT0xk1ahS7du0iOzv7jPHuBRYuXMi//vUvwB2DqFevHgcPHqRt27anPtT69u0blOMR1stcRsnJ0K4dRMiSPMZErVq1agX0uGrVqp26HBMTc+p6TEwMubm5xT6nQYMG3HTTTbz66qv069ePxYsXB1zLhAkTGD9+PGvWrOEf//hHmce8+9cbGxt71hrLwoK+jAoOxBpjwsegQYN48803ycvLIzMzk8WLF9O/nF+7Fy5cyLFjxwDIysri22+/pVWrVgwZMoRXXnnl1H3+XTf+Dh8+TIsWbiX3mTMLF/KtU6cOWVlZp65fdtllvPDCCwDk5eVx+PDhctUbCAv6MkhPh4wM8H1bNMaEiWuvvZaePXvSq1cvLr30Up544gnOO++8cr1WWloaSUlJ9OzZkwsvvJDbb7+dfv36MXz4cEaMGEFSUhKJiYk89dRTxT7/0Ucf5YYbbqBv3740atTo1O1XX301c+fOJTExkc8//5ypU6fy2Wef0aNHD/r27cv69aFbBszWuimDt96C66+3dehN5bJhwwa6dOnidRnGT3H/JrbWTZAkJ0PVqm44mDHGRAoL+jJITnYh73esxBhjwp4FfYByc90YeuuyMcZEGgv6AK1bB8eO2YFYY0zksaAPkK1YaYyJVBb0AVq+HBo1cpOljDEmkljQByg52S17YPsvGFPxCpYp7t69OzfccMOpSUuB2LZtG6+//nq53jdYK02GavnhQFnQB+DIEdiwwbptjPFKwVo3a9eupWrVqrz44oun3V/SMgElBX1pywuUtn58pLBFzQKQkgKqdiDWGNLug4NBXqc4PhH6Br5a2qBBg1i9ejWLFi3i4YcfJj4+nq+//poNGzYwceJEFi1axMmTJ7n77ru58847mThxIhs2bCAxMZGxY8cSHx/P22+/zdGjR8nLy+ODDz5g5MiRHDx4kJycHB5//HFGjhwJQO3atTl69CiLFi3i0UcfpVGjRqxdu5a+ffsya9YsRIS0tDTuv/9+jh49SqNGjZgxYwbNmjUjLS2NW2+9FeC0ZY+9YEEfAFux0pjwkJuby/z58xk+fDgAK1asYO3atbRt25Zp06ZRr149UlJSOHnyJAMHDmTo0KFMmjSJp556ivfffx+AGTNmsGLFClavXk2DBg3Izc1l7ty51K1bl3379jFgwABGjBhxxt6sX331FevWraN58+YMHDiQL774ggsuuIAJEybw7rvv0rhxY958800eeughpk+fzi233MJzzz3HxRdfzG9+85sK/135CyjoRWQ4MBWIBV5W1UlF7r8ZeBLI8N30nKq+7LtvLPA73+2Pq+pMIszy5dCpE9Sv73UlxnisDC3vYPJfj37QoEHcdtttLF26lP79+59aBviTTz5h9erVzJkzB3CLi23atImqVaue8XpDhgw5tcywqvLggw+yePFiYmJiyMjIYM+ePWesldO/f38SEhIATm1nWL9+fdauXcuQIUMAtzhZs2bNOHToEIcOHTq1Jv5Pf/pT5s+fH4LfTGBKDXoRiQWeB4YA6UCKiMxT1aIr8LypquOLPLcB8HsgCVAgzffcg0GpvgKouha9rwFhjPHA2bYS9F8eWFV59tlnGTZs2GmPWbRoUYnPe+2118jMzCQtLY24uDjatGlT7NLCxS0frKp069aNZcuWnfbYQ4cOBfyzVYRADsb2Bzar6hZVzQZmAyMDfP1hwAJVPeAL9wVA2ERmfj7k5MDx45CVBYcOwb59sHu3W6Vy+3ZYtgz27rUDscaEu2HDhvHCCy+Qk5MDwMaNG/n+++/PWB64qMOHD9OkSRPi4uL47LPP2L59e8Dv2alTJzIzM08FfU5ODuvWraN+/frUr1+fJUuWAO7DxEuBdN20AHb4XU8Hiou960TkYmAj8EtV3XGW57YoZ60l2r8fBg2CvDy3XEFubumXy7Jwpwf7+RpjyuD2229n27Zt9OnTB1WlcePGvPPOO/Ts2ZPY2Fh69erFzTffTHx8/GnP+/GPf8zVV19Njx49SEpKonPnzgG/Z9WqVZkzZw733HMPhw8fJjc3l/vuu49u3brxyiuvcOuttyIinh+MLXWZYhG5Hhiuqrf7rv8UuMC/m0ZEGgJHVfWkiNwJjFLVS0Xk10B1VX3c97iHgeOq+lSR9xgHjANo1apV37J8ohY4cgRuuw2qVHGn2NjAL5d2f6NGcOWVZS7JmKhgyxSHn7IuUxxIiz4DaOl3PYHCg64AqOp+v6svA0/4PfeHRZ67qOgbqOo0YBq49egDqOkMdevCv/9dnmcaY0x0C6SPPgXoICJtRaQqMBqY5/8AEWnmd3UEsMF3+WNgqIjEi0g8MNR3mzHGmApSaoteVXNFZDwuoGOB6aq6TkQeA1JVdR5wj4iMAHKBA8DNvuceEJE/4j4sAB5T1eI3WjTGhC1VPWNcufFGeXYFtK0EjTEl2rp1K3Xq1KFhw4YW9h5TVfbv309WVtap+QMFzrWP3hhTiSUkJJCenk5mZqbXpRigevXqpyZuBcqC3hhTori4uDNajyay2OqVxhgT5SzojTEmylnQG2NMlAu7UTcikgmUfWpsaDUC9nldRBlEUr2RVCtEVr2RVCtEVr3hWGtrVW1c3B1hF/ThSERSzzZsKRxFUr2RVCtEVr2RVCtEVr2RVCtY140xxkQ9C3pjjIlyFvSBmeZ1AWUUSfVGUq0QWfVGUq0QWfVGUq3WR2+MMdHOWvTGGBPlLOiNMSbKWdCXQERaishnIrJeRNaJyL1e11QaEYkVka9E5H2vaymNiNQXkTki8rWIbBCRC72u6WxE5Je+/wNrReQNEanudU3+RGS6iOwVkbV+tzUQkQUissl3Hl/Sa1Sks9T7pO//wmoRmSsi9b2ssUBxtfrd9ysRURFp5EVtgbKgL1ku8CtV7QoMAO4Wka4e11Saeync+CXcTQU+UtXOQC/CtG4RaQHcAySpanfcvgyjva3qDDOA4UVumwj8R1U7AP/xXQ8XMziz3gVAd1Xtidt7+oGKLuosZnBmrYhIS9xmSt9VdEFlZUFfAlXdpaorfJezcEEUks3Ng0FEEoAf4bZzDGsiUg+4GPgngKpmq+ohb6sqURWghohUAWoCOz2u5zSquhi36Y+/kcBM3+WZwDUVWlQJiqtXVT9R1Vzf1eW4rUc9d5bfLcBk4LdA2I9osaAPkIi0AXoDyd5WUqIpuP94+V4XEoC2QCbwiq+r6WURqeV1UcVR1QzgKVzLbRdwWFU/8baqgDRV1V2+y7uBpl4WU0a3AvO9LuJsRGQkkKGqq7yuJRAW9AEQkdrAW8B9qnrE63qKIyJXAXtVNc3rWgJUBegDvKCqvYHvCa+uhVN8fdsjcR9OzYFaIvITb6sqG3XjqMO+5QkgIg/huk1f87qW4ohITeBB4BGvawmUBX0pRCQOF/KvqerbXtdTgoHACBHZBswGLhWRWd6WVKJ0IF1VC74hzcEFfzi6HNiqqpmqmgO8DVzkcU2B2CMizQB853s9rqdUInIzcBXwYw3fST7tcR/6q3x/bwnAChE5z9OqSmBBXwJxG2T+E9igqn/zup6SqOoDqpqgqm1wBwoXqmrYtjpVdTewQ0Q6+W66DFjvYUkl+Q4YICI1ff8nLiNMDxwXMQ8Y67s8FnjXw1pKJSLDcV2PI1T1mNf1nI2qrlHVJqraxvf3lg708f2fDksW9CUbCPwU1zpe6Ttd6XVRUWQC8JqIrAYSgT97XE+xfN865gArgDW4v5uwmgIvIm8Ay4BOIpIuIrcBk4AhIrIJ961kkpc1+jtLvc8BdYAFvr+1Fz0t0ucstUYUWwLBGGOinLXojTEmylnQG2NMlLOgN8aYKGdBb4wxUc6C3hhjopwFvTHGRDkLemOMiXL/D/y5bSigEOvQAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6GMoXo2NXkM",
        "outputId": "2f5c14d7-5b24-4406-ba95-4261d537f7ef"
      },
      "source": [
        "print(\"Initial and final accuracy - from scratch: \",from_scratch_valid_acc[0],\" -> \", from_scratch_valid_acc[-1])\n",
        "print(\"Initial and final accuracy - pretrained: \",pretrained_valid_acc[0], \" -> \", pretrained_valid_acc[-1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial and final accuracy - from scratch:  0.4995  ->  0.7915\n",
            "Initial and final accuracy - pretrained:  0.6975  ->  0.8125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u94LhVxcNb0x"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}